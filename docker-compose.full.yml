version: '3.8'

services:
  # Graph RAG Backend API
  api:
    build: ./graph-rag-backend
    container_name: graphrag-api
    ports:
      - "8000:8000"
    environment:
      - GRAPH_DB_TYPE=neo4j
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=graphrag123
      - LLM_PROVIDER=ollama
      - OLLAMA_ENDPOINT=http://ollama:11434/api/generate
    depends_on:
      - neo4j
      - ollama
    volumes:
      - ./graph-rag-backend/uploads:/app/uploads
      - ./graph-rag-backend/vector_store:/app/vector_store
    networks:
      - graphrag-network

  # Graph RAG Frontend
  frontend:
    build: ./graph-rag-frontend
    container_name: graphrag-frontend
    ports:
      - "3000:3000"
    depends_on:
      - api
    networks:
      - graphrag-network

  # Neo4j Graph Database
  neo4j:
    image: neo4j:5.14-community
    container_name: graphrag-neo4j
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    environment:
      - NEO4J_AUTH=neo4j/graphrag123
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_dbms_memory_heap_initial__size=512m
      - NEO4J_dbms_memory_heap_max__size=2G
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
    networks:
      - graphrag-network

  # Ollama for Local LLM
  ollama:
    image: ollama/ollama:latest
    container_name: graphrag-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    networks:
      - graphrag-network
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  neo4j-data:
  neo4j-logs:
  ollama-data:

networks:
  graphrag-network:
    driver: bridge
